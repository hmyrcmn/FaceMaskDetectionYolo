{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmt0w05LVyYh5e8XVxkADx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmyrcmn/FaceMaskDetectionYolo/blob/main/denemeMutfak.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oIXU4MtiHrJf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Veri setinin yolu\n",
        "temiz_yolu = '/content/clean'\n",
        "kirli_yolu = '/content/dirty'\n",
        "\n",
        "def load_images(path):\n",
        "    images = []\n",
        "    for filename in os.listdir(path):\n",
        "        img = cv2.imread(os.path.join(path, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (128, 128))\n",
        "            images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "temiz_goruntuler = load_images(temiz_yolu)\n",
        "kirli_goruntuler = load_images(kirli_yolu)\n",
        "\n",
        "# Etiketler oluştur\n",
        "temiz_labels = np.zeros((temiz_goruntuler.shape[0], 1))\n",
        "kirli_labels = np.ones((kirli_goruntuler.shape[0], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_siamese_model(input_shape):\n",
        "    input = Input(input_shape)\n",
        "\n",
        "    x = Conv2D(64, (10, 10), activation='relu')(input)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(128, (7, 7), activation='relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(128, (4, 4), activation='relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(256, (4, 4), activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(4096, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(input, x)\n",
        "    return model\n",
        "\n",
        "def siamese_network(input_shape):\n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "\n",
        "    model = build_siamese_model(input_shape)\n",
        "\n",
        "    encoded_left = model(left_input)\n",
        "    encoded_right = model(right_input)\n",
        "\n",
        "    L1_layer = Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_left, encoded_right])\n",
        "\n",
        "    prediction = Dense(1, activation='sigmoid')(L1_distance)\n",
        "    siamese_net = Model(inputs=[left_input, right_input], outputs=prediction)\n",
        "\n",
        "    return siamese_net\n",
        "\n",
        "input_shape = (128, 128, 3)\n",
        "model = siamese_network(input_shape)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "84FnhDqvYroD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veri çiftleri oluştur\n",
        "def create_pairs(temiz, kirli):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "    for t_img in temiz:\n",
        "        for k_img in kirli:\n",
        "            pairs += [[t_img, k_img]]\n",
        "            labels += [1]  # farklı oldukları için etiket 1\n",
        "\n",
        "    for i in range(len(temiz)):\n",
        "        for j in range(i + 1, len(temiz)):\n",
        "            pairs += [[temiz[i], temiz[j]]]\n",
        "            labels += [0]  # aynı oldukları için etiket 0\n",
        "\n",
        "    for i in range(len(kirli)):\n",
        "        for j in range(i + 1, len(kirli)):\n",
        "            pairs += [[kirli[i], kirli[j]]]\n",
        "            labels += [0]  # aynı oldukları için etiket 0\n",
        "\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "pairs, labels = create_pairs(temiz_goruntuler, kirli_goruntuler)\n",
        "\n",
        "# Verileri karıştır\n",
        "indices = np.arange(len(labels))\n",
        "np.random.shuffle(indices)\n",
        "pairs = pairs[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "left_images = pairs[:, 0]\n",
        "right_images = pairs[:, 1]\n",
        "\n",
        "# Modeli eğitin\n",
        "model.fit([left_images, right_images], labels, epochs=20, batch_size=16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDqh9knwYvUm",
        "outputId": "6171e4dd-bbe0-4ad1-99a0-a33ffd66899e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 0.6779\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.6667 - loss: 0.6895\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.5000 - loss: 0.6896\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - accuracy: 0.5000 - loss: 0.6921\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 0.6887\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.6667 - loss: 0.6920\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step - accuracy: 0.5000 - loss: 0.6933\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - accuracy: 0.3333 - loss: 0.6966\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.1667 - loss: 0.7005\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8333 - loss: 0.6803\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 0.6874\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - accuracy: 0.0000e+00 - loss: 0.6979\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - accuracy: 0.8333 - loss: 0.6789\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.5000 - loss: 0.6975\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.6667 - loss: 0.6880\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step - accuracy: 0.6667 - loss: 0.6936\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - accuracy: 0.6667 - loss: 0.6837\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.3333 - loss: 0.6980\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 0.7026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ae1a8bb3070>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "aIIGD3P7bNn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (128, 128))  # Modelin eğitim boyutuna uygun olarak yeniden boyutlandırma\n",
        "    img = np.array(img, dtype=np.float32)\n",
        "    img /= 255.0  # Normalizasyon\n",
        "    return img\n",
        "\n",
        "# Test için kullanılacak resim\n",
        "test_image = load_image('/content/clean/mutfak1.jpg')  # Temiz veya kirli resim dosyasının yolu\n"
      ],
      "metadata": {
        "id": "o9gpnAbpbNav"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_cleanliness(model, image):\n",
        "    # Tek görüntü girişine uygun hale getirme\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    # Tahmin yapma\n",
        "    prediction = model.predict([image, image])  # Kendisiyle karşılaştırarak tahmin yapıyoruz\n",
        "    return prediction[0][0]\n",
        "\n",
        "# Görüntünün temiz mi kirli mi olduğunu tahmin etme\n",
        "prediction_score = predict_cleanliness(model, test_image)\n",
        "print(f'Tahmin Skoru: {prediction_score}')\n",
        "\n",
        "if prediction_score < 0.5:  # 0.5'ten düşükse resim kirli\n",
        "    print(\"Resim kirli.\")\n",
        "else:  # 0.5'ten yüksekse resim temiz\n",
        "    print(\"Resim temiz.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3B8KWy_ZQTZ",
        "outputId": "d4d49acf-956b-484d-b955-41f1e04d6d49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "Tahmin Skoru: 0.4996390640735626\n",
            "Resim kirli.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Siamese Network modelini oluştur\n",
        "def build_siamese_model(input_shape):\n",
        "    input = Input(input_shape)\n",
        "    x = Conv2D(64, (10, 10), activation='relu')(input)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(128, (7, 7), activation='relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(128, (4, 4), activation='relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(256, (4, 4), activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(4096, activation='sigmoid')(x)\n",
        "    model = Model(input, x)\n",
        "    return model\n",
        "\n",
        "def siamese_network(input_shape):\n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "    model = build_siamese_model(input_shape)\n",
        "    encoded_left = model(left_input)\n",
        "    encoded_right = model(right_input)\n",
        "    L1_layer = Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_left, encoded_right])\n",
        "    prediction = Dense(1, activation='sigmoid')(L1_distance)\n",
        "    siamese_net = Model(inputs=[left_input, right_input], outputs=prediction)\n",
        "    return siamese_net\n",
        "\n",
        "input_shape = (128, 128, 3)\n",
        "model = siamese_network(input_shape)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Veri setini hazırlayın\n",
        "def load_data():\n",
        "    clean_images = []  # Temiz resimler için liste\n",
        "    dirty_images = []  # Kirli resimler için liste\n",
        "\n",
        "    # Temiz resimleri yükle\n",
        "    for filename in os.listdir('temiz'):\n",
        "        img = cv2.imread(os.path.join('temiz', filename))\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        clean_images.append(img)\n",
        "\n",
        "    # Kirli resimleri yükle\n",
        "    for filename in os.listdir('kirli'):\n",
        "        img = cv2.imread(os.path.join('kirli', filename))\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        dirty_images.append(img)\n",
        "\n",
        "    return np.array(clean_images), np.array(dirty_images)\n",
        "\n",
        "clean_images, dirty_images = load_data()\n",
        "\n",
        "# Eğitim ve doğrulama için çiftler oluştur\n",
        "def create_pairs(clean_images, dirty_images):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "    num_images = min(len(clean_images), len(dirty_images))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        pairs.append([clean_images[i], dirty_images[i]])\n",
        "        labels.append(0)  # Farklı\n",
        "\n",
        "        pairs.append([clean_images[i], clean_images[i]])\n",
        "        labels.append(1)  # Aynı\n",
        "\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "pairs, labels = create_pairs(clean_images, dirty_images)\n",
        "\n",
        "# Modeli eğit\n",
        "model.fit([pairs[:, 0], pairs[:, 1]], labels, epochs=20, batch_size=16)\n",
        "\n",
        "# Modeli kullanarak iki resmi karşılaştır\n",
        "def compare_images(img1, img2):\n",
        "    img1 = cv2.resize(img1, (128, 128))\n",
        "    img2 = cv2.resize(img2, (128, 128))\n",
        "    similarity = model.predict([np.array([img1]), np.array([img2])])\n",
        "    return similarity[0][0]\n",
        "\n",
        "# Örnek karşılaştırma\n",
        "test_img1 = cv2.imread('temiz/test.jpg')\n",
        "test_img2 = cv2.imread('kirli/test.jpg')\n",
        "similarity_score = compare_images(test_img1, test_img2)\n",
        "print(f'Benzerlik Skoru: {similarity_score}')\n"
      ],
      "metadata": {
        "id": "T1CVO1iTYt6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# new\n"
      ],
      "metadata": {
        "id": "kEIPNv4Ngci8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "import numpy as np\n",
        "\n",
        "# Siamese ağda kullanılacak temel CNN modeli\n",
        "def create_base_network(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu')(inputs)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    outputs = layers.Dense(128)(x)  # Öznitelik vektörü (embedding)\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Mesafe fonksiyonu: Euclidean mesafesi\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    return tf.sqrt(tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True))\n",
        "\n",
        "# Mesafe fonksiyonu için özel katman\n",
        "def euclidean_distance_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "# Modelin eğitimi için contrastive loss fonksiyonu\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    square_pred = tf.square(y_pred)\n",
        "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
        "    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
        "\n",
        "# Verilerin şekli (örnek: 128x128x3 boyutunda mutfak görselleri)\n",
        "input_shape = (128, 128, 3)\n",
        "\n",
        "# İkiz ağlar (aynı CNN yapısı her iki giriş görüntüsü için kullanılır)\n",
        "base_network = create_base_network(input_shape)\n",
        "\n",
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "\n",
        "# İki görüntüyü öznitelik vektörlerine dönüştürüyoruz\n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)\n",
        "\n",
        "# Mesafe hesaplanıyor\n",
        "distance = layers.Lambda(euclidean_distance,\n",
        "                         output_shape=euclidean_distance_output_shape)([processed_a, processed_b])\n",
        "\n",
        "# Model oluşturuluyor\n",
        "model = Model([input_a, input_b], distance)\n",
        "\n",
        "# Model derleniyor\n",
        "model.compile(loss=contrastive_loss, optimizer='adam')\n",
        "\n",
        "# Örnek veriler\n",
        "# İkiz görüntü çiftleri (temiz mutfak ve kirli mutfak çiftleri)\n",
        "# Bu kısımda kendi veri setinizi kullanmalısınız\n",
        "X_train_a = np.random.random((1000, 128, 128, 3))  # 1000 adet temiz mutfak görseli\n",
        "X_train_b = np.random.random((1000, 128, 128, 3))  # 1000 adet kirli mutfak görseli\n",
        "y_train = np.random.randint(0, 2, 1000)  # Temiz (1) veya kirli (0)\n",
        "\n",
        "# Modelin eğitilmesi\n",
        "model.fit([X_train_a, X_train_b], y_train, batch_size=32, epochs=10)\n",
        "\n",
        "# Test için örnek görüntü çiftleri\n",
        "X_test_a = np.random.random((10, 128, 128, 3))\n",
        "X_test_b = np.random.random((10, 128, 128, 3))\n",
        "\n",
        "# Modelin çıktısı, iki görüntü arasındaki mesafeyi verir\n",
        "predictions = model.predict([X_test_a, X_test_b])\n",
        "print(\"Benzerlik skorları:\", predictions)\n"
      ],
      "metadata": {
        "id": "couJNFZOhfxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzXExYvjhftp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lLc33Ow5hfrj",
        "outputId": "c1102dce-d555-47a7-cbe8-5fc515f921ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Verilerin konumları\n",
        "clean_image_folder = '/content/clean'  # Temiz mutfak görüntülerinin olduğu klasör\n",
        "dirty_image_folder = '/content/dirty'  # Kirli mutfak görüntülerinin olduğu klasör\n",
        "\n",
        "# Görselleri yükleme fonksiyonu\n",
        "def load_images_from_folder(folder, img_size=(128, 128)):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = load_img(img_path, target_size=img_size)\n",
        "        img_array = img_to_array(img)\n",
        "        images.append(img_array)\n",
        "    return np.array(images)\n",
        "\n",
        "# Temiz ve kirli mutfak görsellerini yükleme\n",
        "clean_images = load_images_from_folder(clean_image_folder)\n",
        "dirty_images = load_images_from_folder(dirty_image_folder)\n",
        "\n",
        "# Etiketler (clean = 1, dirty = 0)\n",
        "clean_labels = np.ones(len(clean_images))\n",
        "dirty_labels = np.zeros(len(dirty_images))\n",
        "\n",
        "# Verileri ve etiketleri birleştirip train/test seti oluşturma\n",
        "X = np.concatenate([clean_images, dirty_images], axis=0)\n",
        "y = np.concatenate([clean_labels, dirty_labels], axis=0)\n",
        "\n",
        "# Train/test seti oluşturma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modeli beslemek için uygun formatta çiftler oluşturma (Siamese için)\n",
        "def make_pairs(images, labels):\n",
        "    pairs = []\n",
        "    labels_pairs = []\n",
        "    num_classes = len(np.unique(labels))\n",
        "\n",
        "    for idx1 in range(len(images)):\n",
        "        current_image = images[idx1]\n",
        "        label = labels[idx1]\n",
        "\n",
        "        # Aynı sınıftan bir görüntü ile çift\n",
        "        idx2 = np.random.choice(np.where(labels == label)[0])\n",
        "        positive_image = images[idx2]\n",
        "        pairs += [[current_image, positive_image]]\n",
        "        labels_pairs += [1]  # Benzer çift\n",
        "\n",
        "        # Farklı sınıftan bir görüntü ile çift\n",
        "        idx2 = np.random.choice(np.where(labels != label)[0])\n",
        "        negative_image = images[idx2]\n",
        "        pairs += [[current_image, negative_image]]\n",
        "        labels_pairs += [0]  # Farklı çift\n",
        "\n",
        "    return np.array(pairs), np.array(labels_pairs)\n",
        "\n",
        "# Eğitim ve test verilerinden çiftler oluşturma\n",
        "train_pairs, train_labels = make_pairs(X_train, y_train)\n",
        "test_pairs, test_labels = make_pairs(X_test, y_test)\n",
        "\n",
        "# Eğitim verilerini modele uygun hale getirme,\n",
        "\n",
        "X_train_a = train_pairs[:, 0]  # İlk görüntü\n",
        "X_train_b = train_pairs[:, 1]  # İkinci görüntü\n",
        "y_train = train_labels\n",
        "\n",
        "X_test_a = test_pairs[:, 0]\n",
        "X_test_b = test_pairs[:, 1]\n",
        "y_test = test_labels\n",
        "\n",
        "# Verileri normalize etme\n",
        "X_train_a = X_train_a / 255.0\n",
        "X_train_b = X_train_b / 255.0\n",
        "X_test_a = X_test_a / 255.0\n",
        "X_test_b = X_test_b / 255.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "rnk9NbQEhfpf",
        "outputId": "0cfea138-1cf0-47a6-f14d-24939b4f0c74"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'a' cannot be empty unless no samples are taken",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6e3a1cd84064>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Eğitim ve test verilerinden çiftler oluşturma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mtrain_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtest_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Eğitim verilerini modele uygun hale getirme,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-6e3a1cd84064>\u001b[0m in \u001b[0;36mmake_pairs\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Farklı sınıftan bir görüntü ile çift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0midx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mnegative_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mpairs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_image\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli eğitme\n",
        "model.fit([X_train_a, X_train_b], y_train, batch_size=32, epochs=10, validation_data=([X_test_a, X_test_b], y_test))\n",
        "\n",
        "# Test için tahminler\n",
        "predictions = model.predict([X_test_a, X_test_b])\n",
        "print(\"Benzerlik skorları:\", predictions)\n"
      ],
      "metadata": {
        "id": "mZWbk3cLge0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cOg4d7-hmrVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZPyNdtlAmrSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Verilerin konumları\n",
        "clean_image_folder = '/content/C'  # Temiz mutfak görüntülerinin olduğu klasör\n",
        "dirty_image_folder = '/content/d'  # Kirli mutfak görüntülerinin olduğu klasör\n",
        "\n",
        "# Görselleri yükleme fonksiyonu\n",
        "def load_images_from_folder(folder, img_size=(128, 128)):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = load_img(img_path, target_size=img_size)\n",
        "        img_array = img_to_array(img)\n",
        "        images.append(img_array)\n",
        "    return np.array(images)\n",
        "\n",
        "# Temiz ve kirli mutfak görsellerini yükleme\n",
        "clean_images = load_images_from_folder(clean_image_folder)\n",
        "dirty_images = load_images_from_folder(dirty_image_folder)\n",
        "\n",
        "# Etiketler (clean = 1, dirty = 0)\n",
        "clean_labels = np.ones(len(clean_images))\n",
        "dirty_labels = np.zeros(len(dirty_images))\n",
        "\n",
        "# Verileri ve etiketleri birleştirip train/test seti oluşturma\n",
        "X = np.concatenate([clean_images, dirty_images], axis=0)\n",
        "y = np.concatenate([clean_labels, dirty_labels], axis=0)\n",
        "\n",
        "# Train/test seti oluşturma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verileri normalleştirme\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "def make_pairs(images, labels):\n",
        "    pairs = []\n",
        "    labels_pairs = []\n",
        "    unique_labels = np.unique(labels)\n",
        "\n",
        "    for idx1 in range(len(images)):\n",
        "        current_image = images[idx1]\n",
        "        label = labels[idx1]\n",
        "\n",
        "        # Aynı sınıftan bir görüntü ile çift\n",
        "        idx2 = np.random.choice(np.where(labels == label)[0])\n",
        "        positive_image = images[idx2]\n",
        "        pairs += [[current_image, positive_image]]\n",
        "        labels_pairs += [1]  # Benzer çift\n",
        "\n",
        "        # Farklı sınıftan bir görüntü ile çift (Eğer farklı sınıftan veri varsa)\n",
        "        other_labels = unique_labels[unique_labels != label]\n",
        "        if len(other_labels) > 0:  # Farklı sınıf varsa devam et\n",
        "            negative_label = np.random.choice(other_labels)\n",
        "            idx2 = np.random.choice(np.where(labels == negative_label)[0])\n",
        "            negative_image = images[idx2]\n",
        "            pairs += [[current_image, negative_image]]\n",
        "            labels_pairs += [0]  # Farklı çift\n",
        "\n",
        "    return np.array(pairs), np.array(labels_pairs)\n",
        "\n",
        "\n",
        "# Eğitim ve test verilerinden çiftler oluşturma\n",
        "train_pairs, train_labels = make_pairs(X_train, y_train)\n",
        "test_pairs, test_labels = make_pairs(X_test, y_test)\n",
        "\n",
        "X_train_a = train_pairs[:, 0]\n",
        "X_train_b = train_pairs[:, 1]\n",
        "X_test_a = test_pairs[:, 0]\n",
        "X_test_b = test_pairs[:, 1]\n",
        "\n",
        "# Modeli normalize etme\n",
        "X_train_a = X_train_a / 255.0\n",
        "X_train_b = X_train_b / 255.0\n",
        "X_test_a = X_test_a / 255.0\n",
        "X_test_b = X_test_b / 255.0\n",
        "\n",
        "# Siamese network'in temelini oluşturan CNN modeli\n",
        "def create_base_model(input_shape):\n",
        "    input = Input(shape=input_shape)\n",
        "    x = Conv2D(64, (10, 10), activation='relu')(input)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(128, (7, 7), activation='relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(128, (4, 4), activation='relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(256, (4, 4), activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(4096, activation='sigmoid')(x)\n",
        "    return Model(input, x)\n",
        "\n",
        "# İki görüntü arasındaki mesafeyi hesaplayan fonksiyon\n",
        "def euclidean_distance(vectors):\n",
        "    (featsA, featsB) = vectors\n",
        "    sum_squared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
        "\n",
        "# Modeli oluşturma\n",
        "input_shape = (128, 128, 3)  # Görüntü boyutları\n",
        "base_model = create_base_model(input_shape)\n",
        "\n",
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "\n",
        "feats_a = base_model(input_a)\n",
        "feats_b = base_model(input_b)\n",
        "\n",
        "distance = Lambda(euclidean_distance)([feats_a, feats_b])\n",
        "\n",
        "model = Model(inputs=[input_a, input_b], outputs=distance)\n",
        "\n",
        "# Modeli derleme\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Modeli eğitme\n",
        "model.fit([X_train_a, X_train_b], train_labels, batch_size=128, epochs=100, validation_data=([X_test_a, X_test_b], test_labels))\n",
        "\n",
        "# Test için tahminler\n",
        "predictions = model.predict([X_test_a, X_test_b])\n",
        "print(\"Benzerlik skorları:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAYGLA8Hm6ju",
        "outputId": "9cf621b8-c526-4cd8-8166-f236d80a9baa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step - accuracy: 0.5000 - loss: 4.0273 - val_accuracy: 0.5000 - val_loss: 4.0298\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 3.8003 - val_accuracy: 0.5000 - val_loss: 4.0302\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 2.9622 - val_accuracy: 0.5000 - val_loss: 4.0320\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 2.2702 - val_accuracy: 0.5000 - val_loss: 4.0371\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.5000 - loss: 1.7231 - val_accuracy: 0.5000 - val_loss: 4.0475\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 1.3719 - val_accuracy: 0.5000 - val_loss: 4.0674\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 1.1293 - val_accuracy: 0.5000 - val_loss: 4.1347\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7500 - loss: 0.9042 - val_accuracy: 0.5000 - val_loss: 4.1940\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8125 - loss: 0.8945 - val_accuracy: 0.5000 - val_loss: 4.0720\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 1.1460 - val_accuracy: 0.5000 - val_loss: 4.1389\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.7500 - loss: 0.9284 - val_accuracy: 0.5000 - val_loss: 4.1112\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6250 - loss: 1.0031 - val_accuracy: 0.5000 - val_loss: 4.0866\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 1.0992 - val_accuracy: 0.5000 - val_loss: 4.0950\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.6250 - loss: 1.0644 - val_accuracy: 0.5000 - val_loss: 4.0719\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 1.1296 - val_accuracy: 0.5000 - val_loss: 4.0890\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 1.0707 - val_accuracy: 0.5000 - val_loss: 4.0521\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.5000 - loss: 1.5935 - val_accuracy: 0.5000 - val_loss: 4.0726\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step - accuracy: 0.5000 - loss: 1.1105 - val_accuracy: 0.5000 - val_loss: 4.1406\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6875 - loss: 0.9682 - val_accuracy: 0.5000 - val_loss: 4.1285\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.6250 - loss: 1.0868 - val_accuracy: 0.5000 - val_loss: 4.1638\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.7500 - loss: 0.9345 - val_accuracy: 0.5000 - val_loss: 4.1520\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.7500 - loss: 0.9378 - val_accuracy: 0.5000 - val_loss: 4.1390\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.7500 - loss: 0.9675 - val_accuracy: 0.5000 - val_loss: 4.1477\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.6875 - loss: 0.9524 - val_accuracy: 0.5000 - val_loss: 4.1231\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.7500 - loss: 0.9623 - val_accuracy: 0.5000 - val_loss: 4.1162\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.5625 - loss: 0.9991 - val_accuracy: 0.5000 - val_loss: 4.1443\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8125 - loss: 0.9523 - val_accuracy: 0.5000 - val_loss: 4.1231\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.6875 - loss: 0.9838 - val_accuracy: 0.5000 - val_loss: 4.1480\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.6875 - loss: 0.9717 - val_accuracy: 0.5000 - val_loss: 4.1900\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7500 - loss: 0.8702 - val_accuracy: 0.5000 - val_loss: 4.1758\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7500 - loss: 0.9082 - val_accuracy: 0.5000 - val_loss: 4.2156\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8125 - loss: 0.8570 - val_accuracy: 0.5000 - val_loss: 4.1737\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6250 - loss: 0.9814 - val_accuracy: 0.5000 - val_loss: 4.2259\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7500 - loss: 0.9080 - val_accuracy: 0.5000 - val_loss: 4.0993\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.5000 - loss: 1.0598 - val_accuracy: 0.5000 - val_loss: 4.1543\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - accuracy: 0.6875 - loss: 0.9479 - val_accuracy: 0.5000 - val_loss: 4.1511\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.6250 - loss: 0.9826 - val_accuracy: 0.5000 - val_loss: 4.1457\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5625 - loss: 1.0496 - val_accuracy: 0.5000 - val_loss: 4.0401\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 1.4645 - val_accuracy: 0.5000 - val_loss: 4.1464\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7500 - loss: 0.9856 - val_accuracy: 0.5000 - val_loss: 4.0298\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 3.4574 - val_accuracy: 0.5000 - val_loss: 4.2113\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.7500 - loss: 0.9085 - val_accuracy: 0.5000 - val_loss: 4.0612\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 1.1756 - val_accuracy: 0.5000 - val_loss: 4.1831\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.7500 - loss: 0.9287 - val_accuracy: 0.5000 - val_loss: 4.1247\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.6250 - loss: 1.0347 - val_accuracy: 0.5000 - val_loss: 4.1751\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.7500 - loss: 0.9134 - val_accuracy: 0.5000 - val_loss: 4.1418\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8750 - loss: 0.8705 - val_accuracy: 0.5000 - val_loss: 4.2063\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.7500 - loss: 0.9131 - val_accuracy: 0.5000 - val_loss: 4.0546\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 1.1926 - val_accuracy: 0.5000 - val_loss: 4.0756\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.6250 - loss: 1.0568 - val_accuracy: 0.5000 - val_loss: 4.0653\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.6250 - loss: 1.0200 - val_accuracy: 0.5000 - val_loss: 4.1078\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8750 - loss: 0.8960 - val_accuracy: 0.5000 - val_loss: 4.1451\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.8125 - loss: 0.8842 - val_accuracy: 0.5000 - val_loss: 4.0827\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.7500 - loss: 0.9649 - val_accuracy: 0.5000 - val_loss: 4.0729\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8125 - loss: 0.9623 - val_accuracy: 0.5000 - val_loss: 4.0845\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8750 - loss: 0.8945 - val_accuracy: 0.5000 - val_loss: 4.1120\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8750 - loss: 0.8224 - val_accuracy: 0.5000 - val_loss: 4.1392\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8125 - loss: 0.8283 - val_accuracy: 0.5000 - val_loss: 4.1144\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8750 - loss: 0.8455 - val_accuracy: 0.5000 - val_loss: 4.1290\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8125 - loss: 0.8142 - val_accuracy: 0.5000 - val_loss: 4.1067\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8125 - loss: 0.7960 - val_accuracy: 0.5000 - val_loss: 4.0990\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8750 - loss: 0.7945 - val_accuracy: 0.5000 - val_loss: 4.0875\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8750 - loss: 0.7983 - val_accuracy: 0.5000 - val_loss: 4.0917\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8125 - loss: 0.7857 - val_accuracy: 0.5000 - val_loss: 4.0756\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8125 - loss: 0.7854 - val_accuracy: 0.5000 - val_loss: 4.0739\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8125 - loss: 0.7793 - val_accuracy: 0.5000 - val_loss: 4.0666\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.8125 - loss: 0.7748 - val_accuracy: 0.5000 - val_loss: 4.0625\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.8125 - loss: 0.7741 - val_accuracy: 0.5000 - val_loss: 4.0631\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8125 - loss: 0.7829 - val_accuracy: 0.5000 - val_loss: 4.0559\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.8125 - loss: 0.7906 - val_accuracy: 0.5000 - val_loss: 4.0558\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - accuracy: 0.8125 - loss: 0.7787 - val_accuracy: 0.5000 - val_loss: 4.0571\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.8125 - loss: 0.7696 - val_accuracy: 0.5000 - val_loss: 4.0552\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8125 - loss: 0.7696 - val_accuracy: 0.5000 - val_loss: 4.0559\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8125 - loss: 0.7664 - val_accuracy: 0.5000 - val_loss: 4.0569\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8125 - loss: 0.7671 - val_accuracy: 0.5000 - val_loss: 4.0540\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8750 - loss: 0.7923 - val_accuracy: 0.5000 - val_loss: 4.0548\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8125 - loss: 0.7683 - val_accuracy: 0.5000 - val_loss: 4.0544\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8125 - loss: 0.7683 - val_accuracy: 0.5000 - val_loss: 4.0532\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8125 - loss: 0.7659 - val_accuracy: 0.5000 - val_loss: 4.0550\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8125 - loss: 0.7751 - val_accuracy: 0.5000 - val_loss: 4.0506\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8750 - loss: 0.7979 - val_accuracy: 0.5000 - val_loss: 4.0518\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8125 - loss: 0.7802 - val_accuracy: 0.5000 - val_loss: 4.0552\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8125 - loss: 0.7653 - val_accuracy: 0.5000 - val_loss: 4.0592\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8125 - loss: 0.7733 - val_accuracy: 0.5000 - val_loss: 4.0557\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.8125 - loss: 0.7725 - val_accuracy: 0.5000 - val_loss: 4.0562\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8125 - loss: 0.7667 - val_accuracy: 0.5000 - val_loss: 4.0572\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.8125 - loss: 0.7657 - val_accuracy: 0.5000 - val_loss: 4.0548\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8125 - loss: 0.7855 - val_accuracy: 0.5000 - val_loss: 4.0547\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8125 - loss: 0.7792 - val_accuracy: 0.5000 - val_loss: 4.0553\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.8125 - loss: 0.7652 - val_accuracy: 0.5000 - val_loss: 4.0565\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8125 - loss: 0.7802 - val_accuracy: 0.5000 - val_loss: 4.0516\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8125 - loss: 0.7866 - val_accuracy: 0.5000 - val_loss: 4.0551\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8125 - loss: 0.7848 - val_accuracy: 0.5000 - val_loss: 4.0621\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8125 - loss: 0.7758 - val_accuracy: 0.5000 - val_loss: 4.0557\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.8125 - loss: 0.7665 - val_accuracy: 0.5000 - val_loss: 4.0583\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.8125 - loss: 0.7721 - val_accuracy: 0.5000 - val_loss: 4.0608\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.8125 - loss: 0.7696 - val_accuracy: 0.5000 - val_loss: 4.0591\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.8125 - loss: 0.7652 - val_accuracy: 0.5000 - val_loss: 4.0581\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.8125 - loss: 0.7649 - val_accuracy: 0.5000 - val_loss: 4.0537\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.8750 - loss: 0.7955 - val_accuracy: 0.5000 - val_loss: 4.0610\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682ms/step\n",
            "Benzerlik skorları: [[0.00031623]\n",
            " [0.06102541]\n",
            " [0.00031623]\n",
            " [0.06102541]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Verilerin konumları\n",
        "clean_image_folder = '/content/C'  # Temiz mutfak görüntülerinin olduğu klasör\n",
        "dirty_image_folder = '/content/d'  # Kirli mutfak görüntülerinin olduğu klasör\n",
        "\n",
        "# Görselleri yükleme fonksiyonu\n",
        "def load_images_from_folder(folder, img_size=(128, 128)):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = load_img(img_path, target_size=img_size)\n",
        "        img_array = img_to_array(img)\n",
        "        images.append(img_array)\n",
        "    return np.array(images)\n",
        "\n",
        "# Temiz ve kirli mutfak görsellerini yükleme\n",
        "clean_images = load_images_from_folder(clean_image_folder)\n",
        "dirty_images = load_images_from_folder(dirty_image_folder)\n",
        "\n",
        "# Etiketler (clean = 1, dirty = 0)\n",
        "clean_labels = np.ones(len(clean_images))\n",
        "dirty_labels = np.zeros(len(dirty_images))\n",
        "\n",
        "# Verileri ve etiketleri birleştirip train/test seti oluşturma\n",
        "X = np.concatenate([clean_images, dirty_images], axis=0)\n",
        "y = np.concatenate([clean_labels, dirty_labels], axis=0)\n",
        "\n",
        "# Train/test seti oluşturma\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verileri normalleştirme\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "def make_pairs(images, labels):\n",
        "    pairs = []\n",
        "    labels_pairs = []\n",
        "    unique_labels = np.unique(labels)\n",
        "\n",
        "    for idx1 in range(len(images)):\n",
        "        current_image = images[idx1]\n",
        "        label = labels[idx1]\n",
        "\n",
        "        # Aynı sınıftan bir görüntü ile çift\n",
        "        idx2 = np.random.choice(np.where(labels == label)[0])\n",
        "        positive_image = images[idx2]\n",
        "        pairs += [[current_image, positive_image]]\n",
        "        labels_pairs += [1]  # Benzer çift\n",
        "\n",
        "        # Farklı sınıftan bir görüntü ile çift (Eğer farklı sınıftan veri varsa)\n",
        "        other_labels = unique_labels[unique_labels != label]\n",
        "        if len(other_labels) > 0:  # Farklı sınıf varsa devam et\n",
        "            negative_label = np.random.choice(other_labels)\n",
        "            idx2 = np.random.choice(np.where(labels == negative_label)[0])\n",
        "            negative_image = images[idx2]\n",
        "            pairs += [[current_image, negative_image]]\n",
        "            labels_pairs += [0]  # Farklı çift\n",
        "\n",
        "    return np.array(pairs), np.array(labels_pairs)\n",
        "\n",
        "\n",
        "# Eğitim ve test verilerinden çiftler oluşturma\n",
        "train_pairs, train_labels = make_pairs(X_train, y_train)\n",
        "test_pairs, test_labels = make_pairs(X_test, y_test)\n",
        "\n",
        "X_train_a = train_pairs[:, 0]\n",
        "X_train_b = train_pairs[:, 1]\n",
        "X_test_a = test_pairs[:, 0]\n",
        "X_test_b = test_pairs[:, 1]\n",
        "\n",
        "# Modeli normalize etme\n",
        "X_train_a = X_train_a / 255.0\n",
        "X_train_b = X_train_b / 255.0\n",
        "X_test_a = X_test_a / 255.0\n",
        "X_test_b = X_test_b / 255.0\n",
        "\n",
        "# Siamese network'in temelini oluşturan CNN modeli\n",
        "def create_base_model(input_shape):\n",
        "    input = Input(shape=input_shape)\n",
        "    x = Conv2D(64, (10, 10), activation='relu')(input)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(128, (7, 7), activation='relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(128, (4, 4), activation='relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Conv2D(256, (4, 4), activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(4096, activation='sigmoid')(x)\n",
        "    return Model(input, x)\n",
        "\n",
        "# İki görüntü arasındaki mesafeyi hesaplayan fonksiyon\n",
        "def euclidean_distance(vectors):\n",
        "    (featsA, featsB) = vectors\n",
        "    sum_squared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
        "\n",
        "# Modeli oluşturma\n",
        "input_shape = (128, 128, 3)  # Görüntü boyutları\n",
        "base_model = create_base_model(input_shape)\n",
        "\n",
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "\n",
        "feats_a = base_model(input_a)\n",
        "feats_b = base_model(input_b)\n",
        "\n",
        "distance = Lambda(euclidean_distance)([feats_a, feats_b])\n",
        "\n",
        "model2 = Model(inputs=[input_a, input_b], outputs=distance)\n",
        "\n",
        "# Modeli derleme\n",
        "model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Modeli eğitme\n",
        "model2.fit([X_train_a, X_train_b], train_labels, batch_size=32, epochs=100, validation_data=([X_test_a, X_test_b], test_labels))\n",
        "\n",
        "# Test için tahminler\n",
        "predictions2 = model2.predict([X_test_a, X_test_b])\n",
        "print(\"Benzerlik skorları:\", predictions2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn1Hkg_sop25",
        "outputId": "88a83737-24d9-4f54-a09b-55334cad8dc9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.5000 - loss: 4.0297 - val_accuracy: 0.5000 - val_loss: 4.0297\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736ms/step\n",
            "Benzerlik skorları: [[0.00031623]\n",
            " [0.00031623]\n",
            " [0.00031623]\n",
            " [0.00031623]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PYFWSV1RvCcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VDTkPGyOvslp"
      }
    }
  ]
}